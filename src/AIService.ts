import OpenAI from 'openai';
import { GoogleGenerativeAI } from '@google/generative-ai';
import fs from 'fs';
import path from 'path';
import { spawn } from 'child_process';
import { instagramGetUrl, InstagramResponse } from "instagram-url-direct"

export interface AIConfig {
  openaiApiKey?: string;
  googleApiKey?: string;
  defaultProvider?: 'openai' | 'google';
  temperature?: number;
  maxTokens?: number;
}

export interface MessageContext {
  username: string;
  messageContent: string;
  conversationHistory?: string[];
  userProfile?: {
    name?: string;
    bio?: string;
    followersCount?: number;
  };
}

export interface AIResponse {
  content: string;
  provider: 'openai' | 'google';
  tokensUsed?: number;
  processingTime: number;
}

export interface MediaAnalysisResult {
  mediaAnalysis: string;
  generatedComment: string;
  processingTime: number;
  mediaPath?: string;
  mediaType: 'video' | 'image';
}

export class AIService {
  private openai?: OpenAI;
  private googleAI?: GoogleGenerativeAI;
  private config: AIConfig;

  constructor(config: AIConfig) {
    this.config = {
      defaultProvider: 'openai',
      temperature: 0.7,
      maxTokens: 150,
      ...config
    };

    // Inicializar OpenAI se a chave foi fornecida
    if (config.openaiApiKey) {
      this.openai = new OpenAI({
        apiKey: config.openaiApiKey
      });
    }

    // Inicializar Google AI se a chave foi fornecida
    if (config.googleApiKey) {
      this.googleAI = new GoogleGenerativeAI(config.googleApiKey);
    }

    if (!config.openaiApiKey && !config.googleApiKey) {
      throw new Error('Pelo menos uma chave de API (OpenAI ou Google) deve ser fornecida');
    }
  }

  /**
   * Gera uma resposta humanizada usando IA
   */
  async generateResponse(
    context: MessageContext,
    provider?: 'openai' | 'google'
  ): Promise<AIResponse> {
    const startTime = Date.now();
    const selectedProvider = provider || this.config.defaultProvider || 'openai';

    try {
      let response: string;

      if (selectedProvider === 'openai' && this.openai) {
        response = await this.generateOpenAIResponse(context);
      } else if (selectedProvider === 'google' && this.googleAI) {
        response = await this.generateGoogleResponse(context);
      } else {
        // Fallback para o provedor dispon√≠vel
        if (this.openai) {
          response = await this.generateOpenAIResponse(context);
        } else if (this.googleAI) {
          response = await this.generateGoogleResponse(context);
        } else {
          throw new Error('Nenhum provedor de IA dispon√≠vel');
        }
      }

      const processingTime = Date.now() - startTime;

      return {
        content: response,
        provider: selectedProvider,
        processingTime
      };
    } catch (error) {
      console.error(`Erro ao gerar resposta com ${selectedProvider}:`, error);
      throw error;
    }
  }

  /**
   * Gera resposta usando OpenAI GPT
   */
  private async generateOpenAIResponse(context: MessageContext): Promise<string> {
    if (!this.openai) {
      throw new Error('OpenAI n√£o est√° configurado');
    }

    const systemPrompt = this.buildSystemPrompt(context);
    const userMessage = this.buildUserMessage(context);

    const completion = await this.openai.chat.completions.create({
      model: 'gpt-5-nano',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userMessage }
      ],
      temperature: this.config.temperature || 0.7,
      max_tokens: this.config.maxTokens || 150,
      presence_penalty: 0.6, // Evita repeti√ß√µes
      frequency_penalty: 0.3  // Varia o vocabul√°rio
    });

    return completion.choices[0]?.message?.content?.trim() || 'Desculpe, n√£o consegui gerar uma resposta.';
  }

  /**
   * Gera resposta usando Google Gemini
   */
  private async generateGoogleResponse(context: MessageContext): Promise<string> {
    if (!this.googleAI) {
      throw new Error('Google AI n√£o est√° configurado');
    }

    const model = this.googleAI.getGenerativeModel({ model: 'gemini-pro' });
    const prompt = this.buildGooglePrompt(context);

    const result = await model.generateContent(prompt);
    const response = await result.response;

    return response.text().trim() || 'Desculpe, n√£o consegui gerar uma resposta.';
  }

  /**
   * Constr√≥i o prompt do sistema para OpenAI
   */
  private buildSystemPrompt(context: MessageContext): string {
    return `Voc√™ √© um assistente de Instagram que responde mensagens de forma natural e humanizada.

Diretrizes importantes:
- Responda de forma casual e amig√°vel, como uma pessoa real
- Use emojis ocasionalmente, mas n√£o exagere
- Mantenha as respostas curtas e diretas (m√°ximo 2-3 frases)
- Adapte o tom baseado no contexto da conversa
- Evite soar rob√≥tico ou muito formal
- Use linguagem brasileira natural
- Se n√£o souber algo espec√≠fico, seja honesto mas √∫til

Perfil do usu√°rio que est√° respondendo:
${context.userProfile ? `Nome: ${context.userProfile.name || 'N√£o informado'}
Bio: ${context.userProfile.bio || 'N√£o informada'}
Seguidores: ${context.userProfile.followersCount || 'N√£o informado'}` : 'Perfil n√£o dispon√≠vel'}

Hist√≥rico da conversa:
${context.conversationHistory?.join('\n') || 'Primeira mensagem da conversa'}`;
  }

  /**
   * Constr√≥i a mensagem do usu√°rio para OpenAI
   */
  private buildUserMessage(context: MessageContext): string {
    return `O usu√°rio @${context.username} enviou: "${context.messageContent}"

Responda de forma natural e humanizada.`;
  }

  /**
   * Constr√≥i o prompt completo para Google Gemini
   */
  private buildGooglePrompt(context: MessageContext): string {
    return `Voc√™ √© um assistente de Instagram que responde mensagens de forma natural e humanizada.

Diretrizes importantes:
- Responda de forma casual e amig√°vel, como uma pessoa real
- Use emojis ocasionalmente, mas n√£o exagere
- Mantenha as respostas curtas e diretas (m√°ximo 2-3 frases)
- Adapte o tom baseado no contexto da conversa
- Evite soar rob√≥tico ou muito formal
- Use linguagem brasileira natural
- Se n√£o souber algo espec√≠fico, seja honesto mas √∫til

Perfil do usu√°rio que est√° respondendo:
${context.userProfile ? `Nome: ${context.userProfile.name || 'N√£o informado'}
Bio: ${context.userProfile.bio || 'N√£o informada'}
Seguidores: ${context.userProfile.followersCount || 'N√£o informado'}` : 'Perfil n√£o dispon√≠vel'}

Hist√≥rico da conversa:
${context.conversationHistory?.join('\n') || 'Primeira mensagem da conversa'}

O usu√°rio @${context.username} enviou: "${context.messageContent}"

Responda de forma natural e humanizada:`;
  }

  /**
   * Gera m√∫ltiplas varia√ß√µes de resposta para escolher a melhor
   */
  async generateMultipleResponses(
    context: MessageContext,
    count: number = 3
  ): Promise<AIResponse[]> {
    const promises = Array.from({ length: count }, () =>
      this.generateResponse(context)
    );

    try {
      return await Promise.all(promises);
    } catch (error) {
      console.error('Erro ao gerar m√∫ltiplas respostas:', error);
      throw error;
    }
  }

  /**
   * Seleciona a melhor resposta baseada em crit√©rios de qualidade
   */
  selectBestResponse(responses: AIResponse[]): AIResponse {
    if (responses.length === 0) {
      throw new Error('Nenhuma resposta fornecida');
    }

    if (responses.length === 1) {
      return responses[0];
    }

    // Crit√©rios de sele√ß√£o:
    // 1. Evitar respostas muito curtas (< 10 caracteres)
    // 2. Evitar respostas muito longas (> 200 caracteres)
    // 3. Preferir respostas com emojis (mas n√£o muitos)
    // 4. Evitar respostas gen√©ricas

    const scoredResponses = responses.map(response => {
      let score = 0;
      const content = response.content;
      const length = content.length;

      // Penalizar respostas muito curtas ou muito longas
      if (length < 10) score -= 3;
      else if (length > 200) score -= 2;
      else if (length >= 20 && length <= 100) score += 2;

      // Bonificar presen√ßa moderada de emojis
      const emojiCount = (content.match(/[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]|[\u{2600}-\u{26FF}]|[\u{2700}-\u{27BF}]/gu) || []).length;
      if (emojiCount === 1 || emojiCount === 2) score += 1;
      else if (emojiCount > 3) score -= 1;

      // Penalizar respostas gen√©ricas
      const genericPhrases = ['obrigado', 'de nada', 'ok', 'tudo bem', 'legal'];
      if (genericPhrases.some(phrase => content.toLowerCase().includes(phrase))) {
        score -= 1;
      }

      // Bonificar tempo de processamento mais r√°pido
      if (response.processingTime < 2000) score += 1;

      return { ...response, score };
    });

    // Retornar a resposta com maior pontua√ß√£o
    return scoredResponses.reduce((best, current) =>
      current.score > best.score ? current : best
    );
  }

  /**
   * Verifica se o servi√ßo est√° configurado corretamente
   */
  isConfigured(): boolean {
    return !!(this.openai || this.googleAI);
  }

  /**
   * Retorna informa√ß√µes sobre os provedores dispon√≠veis
   */
  getAvailableProviders(): string[] {
    const providers: string[] = [];
    if (this.openai) providers.push('openai');
    if (this.googleAI) providers.push('google');
    return providers;
  }

  /**
   * Analisa um v√≠deo do Instagram usando Gemini e gera um coment√°rio
   */
  async analyzeInstagramPost(
    postUrl: string,
    caption?: string,
    username?: string
  ): Promise<MediaAnalysisResult> {
    if (!this.googleAI) {
      throw new Error('Google AI (Gemini) n√£o est√° configurado. Necess√°rio para an√°lise de v√≠deo.');
    }

    const startTime = Date.now();
    let videoPath: string | undefined;

    try {
      console.log(`üé• Iniciando an√°lise de post: ${postUrl}`);

      // 1. Tentar baixar como v√≠deo primeiro
      try {
        videoPath = await this.downloadVideo(postUrl);
        console.log(`üì• V√≠deo baixado: ${videoPath}`);
        return await this.analyzeVideoContent(videoPath, startTime, caption, username);
      } catch (videoError: any) {
        console.log(`‚ÑπÔ∏è N√£o √© um v√≠deo, tentando como imagem...`);

        // 2. Se falhar, tentar como imagem
        try {
          videoPath = await this.downloadImage(postUrl);
          console.log(`üì• Imagem baixada: ${videoPath}`);
          return await this.analyzeImageContent(videoPath, startTime, caption, username);
        } catch (imageError: any) {
          throw new Error(`Falha ao baixar m√≠dia: V√≠deo - ${videoError.message}, Imagem - ${imageError.message}`);
        }
      }

    } catch (error) {
      console.error('‚ùå Erro na an√°lise do post:', error);

      // Limpar arquivo em caso de erro
      // if (videoPath && fs.existsSync(videoPath)) {
      //   fs.unlinkSync(videoPath);
      // }

      throw error;
    }
  }

  /**
   * Analisa conte√∫do de v√≠deo
   */
  private async analyzeVideoContent(
    videoPath: string,
    startTime: number,
    caption?: string,
    username?: string
  ): Promise<MediaAnalysisResult> {
    const model = this.googleAI!.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

    // Ler o arquivo de v√≠deo
    const videoData = fs.readFileSync(videoPath);
    const mimeType = this.getMimeType(videoPath);

    // Criar prompt para an√°lise
    const analysisPrompt = this.buildVideoAnalysisPrompt(caption, username);

    console.log(`ü§ñ Enviando v√≠deo para an√°lise do Gemini...`);

    // Enviar para o Gemini
    const result = await model.generateContent([
      {
        inlineData: {
          data: videoData.toString('base64'),
          mimeType: mimeType
        }
      },
      analysisPrompt
    ]);

    const response = await result.response;
    const mediaAnalysis = response.text();

    console.log(`üìä An√°lise do v√≠deo: ${mediaAnalysis}`);
    console.log(`‚úÖ An√°lise do v√≠deo conclu√≠da`);

    // Gerar coment√°rio baseado na an√°lise
    const generatedComment = await this.generateCommentFromAnalysis(mediaAnalysis, caption, username);

    const processingTime = Date.now() - startTime;

    return {
      mediaAnalysis,
      generatedComment,
      processingTime,
      mediaType: 'video'
    };
  }

  /**
   * Analisa conte√∫do de imagem
   */
  private async analyzeImageContent(
    imagePath: string,
    startTime: number,
    caption?: string,
    username?: string
  ): Promise<MediaAnalysisResult> {
    const model = this.googleAI!.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

    // Ler o arquivo de imagem
    const imageData = fs.readFileSync(imagePath);
    const mimeType = this.getMimeType(imagePath);

    // Criar prompt para an√°lise de imagem
    const analysisPrompt = this.buildImageAnalysisPrompt(caption, username);

    console.log(`ü§ñ Enviando imagem para an√°lise do Gemini...`);

    // Enviar para o Gemini
    const result = await model.generateContent([
      {
        inlineData: {
          data: imageData.toString('base64'),
          mimeType: mimeType
        }
      },
      analysisPrompt
    ]);

    const response = await result.response;
    const mediaAnalysis = response.text();

    console.log(`üìä An√°lise da imagem: ${mediaAnalysis}`);
    console.log(`‚úÖ An√°lise da imagem conclu√≠da`);

    // Gerar coment√°rio baseado na an√°lise
    const generatedComment = await this.generateCommentFromAnalysis(mediaAnalysis, caption, username);

    const processingTime = Date.now() - startTime;

    return {
      mediaAnalysis,
      generatedComment,
      processingTime,
      mediaType: 'image'
    };
  }

  /**
   * Baixa uma imagem do Instagram usando instagram-url-direct
   */
  private async downloadImage(imageUrl: string): Promise<string> {
    const data: InstagramResponse = await instagramGetUrl(imageUrl);
    console.log(data);
    
    const imageDirectUrl = data.media_details[0].url;
    const imageId = this.extractVideoId(imageUrl); // Reutiliza o m√©todo para extrair ID
    const tempDir = path.join(process.cwd(), 'temp_videos');
    
    // Criar diret√≥rio tempor√°rio se n√£o existir
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    
    // Determinar extens√£o da imagem
    const imageExtension = imageDirectUrl.includes('.jpg') ? '.jpg' : '.png';
    const imagePath = path.join(tempDir, `${imageId}${imageExtension}`);
    
    // Baixar a imagem
    const response = await fetch(imageDirectUrl);
    if (!response.ok) {
      throw new Error(`Falha ao baixar imagem: ${response.statusText}`);
    }
    
    const arrayBuffer = await response.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    
    // Salvar a imagem no disco
    fs.writeFileSync(imagePath, buffer);
    
    console.log(`üì• Imagem salva em: ${imagePath}`);
    return imagePath;
  }

  /**
   * Baixa um v√≠deo do Instagram usando yt-dlp
   */
  private async downloadVideo(videoUrl: string): Promise<string> {
    const videoId = this.extractVideoId(videoUrl);
    const tempDir = path.join(process.cwd(), 'temp_videos');

    // Criar diret√≥rio tempor√°rio se n√£o existir
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    const videoPath = path.join(tempDir, `${videoId}.%(ext)s`);
    const ytDlpPath = path.join(process.cwd(), 'yt-dlp', 'yt-dlp.exe');

    // Verificar se o yt-dlp existe
    if (!fs.existsSync(ytDlpPath)) {
      throw new Error(`yt-dlp n√£o encontrado em: ${ytDlpPath}`);
    }

    return new Promise((resolve, reject) => {
      console.log(`üì• Baixando v√≠deo: ${videoUrl}`);

      const args = [
        videoUrl,
        '-o', videoPath,
        '--format', 'best[ext=mp4]/best',
        '--no-playlist',
      ];

      const ytDlp = spawn(ytDlpPath, args, {
        stdio: ['pipe', 'pipe', 'pipe']
      });

      let stdout = '';
      let stderr = '';

      ytDlp.stdout.on('data', (data) => {
        stdout += data.toString();
        console.log(`yt-dlp: ${data.toString().trim()}`);
      });

      ytDlp.stderr.on('data', (data) => {
        stderr += data.toString();
        console.error(`yt-dlp error: ${data.toString().trim()}`);
      });

      ytDlp.on('close', (code) => {
        if (code === 0) {
          // Encontrar o arquivo baixado (yt-dlp pode mudar a extens√£o)
          const files = fs.readdirSync(tempDir).filter(file =>
            file.startsWith(videoId) && (file.endsWith('.mp4') || file.endsWith('.webm') || file.endsWith('.mkv'))
          );

          if (files.length > 0) {
            const downloadedFile = path.join(tempDir, files[0]);
            console.log(`‚úÖ V√≠deo baixado com sucesso: ${downloadedFile}`);
            resolve(downloadedFile);
          } else {
            reject(new Error('Arquivo de v√≠deo n√£o encontrado ap√≥s download'));
          }
        } else {
          reject(new Error(`yt-dlp falhou com c√≥digo ${code}. Stderr: ${stderr}`));
        }
      });

      ytDlp.on('error', (error) => {
        reject(new Error(`Erro ao executar yt-dlp: ${error.message}`));
      });
    });
  }

  /**
   * Extrai ID do v√≠deo da URL do Instagram
   */
  private extractVideoId(url: string): string {
    const match = url.match(/\/(p|reel)\/([^/]+)\//);
    return match ? match[2] : `video_${Date.now()}`;
  }

  /**
   * Determina o MIME type do arquivo de v√≠deo ou imagem
   */
  private getMimeType(filePath: string): string {
    const ext = path.extname(filePath).toLowerCase();
    switch (ext) {
      case '.mp4': return 'video/mp4';
      case '.mov': return 'video/quicktime';
      case '.avi': return 'video/x-msvideo';
      case '.webm': return 'video/webm';
      case '.jpg':
      case '.jpeg': return 'image/jpeg';
      case '.png': return 'image/png';
      case '.webp': return 'image/webp';
      case '.gif': return 'image/gif';
      default: return 'video/mp4'; // fallback
    }
  }

  /**
   * Constr√≥i o prompt para an√°lise de v√≠deo
   */
  private buildVideoAnalysisPrompt(caption?: string, username?: string): string {
    let prompt = `Analise este v√≠deo do Instagram e forne√ßa uma descri√ß√£o detalhada.`;

    if (caption) {
      prompt += `\n\nLegenda do post: "${caption}"`;
      prompt += `\nConsidere como o conte√∫do se relaciona com a legenda.`;
    }

    if (username) {
      prompt += `\n\nEste v√≠deo foi postado por @${username}.`;
    }

    prompt += `\n\nSua an√°lise deve ser:
- Detalhada e precisa
- Em portugu√™s brasileiro`;
    if (caption) {
      prompt += `\n\n- Contextualizada com a legenda`;
    }

    return prompt;
  }

  /**
   * Constr√≥i o prompt para an√°lise de imagem
   */
  private buildImageAnalysisPrompt(caption?: string, username?: string): string {
    let prompt = `Analise esta imagem do Instagram e forne√ßa uma descri√ß√£o detalhada do conte√∫do visual, objetos, pessoas, cen√°rio, cores, composi√ß√£o, estilo e qualquer elemento relevante que voc√™ observar.`;

    if (caption) {
      prompt += `\n\nLegenda do post: "${caption}"`;
      prompt += `\nConsidere como o conte√∫do se relaciona com a legenda.`;
    }

    if (username) {
      prompt += `\n\nEsta imagem foi postada por @${username}.`;
    }

    prompt += `\n\nSua an√°lise deve ser:
- Detalhada e precisa
- Em portugu√™s brasileiro
- Focada em elementos visuais relevantes para gerar coment√°rios engajadores`;
    if (caption) {
      prompt += `\n- Contextualizada com a legenda`;
    }

    return prompt;
  }

  /**
   * Gera um coment√°rio baseado na an√°lise do v√≠deo
   */
  private async generateCommentFromAnalysis(
    videoAnalysis: string,
    caption?: string,
    username?: string
  ): Promise<string> {
    if (!this.googleAI) {
      throw new Error('Google AI n√£o configurado');
    }

    const model = this.googleAI.getGenerativeModel({ model: 'gemini-2.5-pro' });

    let prompt = `Voc√™ √© uma mulher comentando em v√≠deos aleat√≥rios no Instagram para gerar engajamento. Com base na seguinte an√°lise de v√≠deo, gere um coment√°rio natural e engajador para o Instagram:\n\n`;
    prompt += `AN√ÅLISE DO V√çDEO:\n${videoAnalysis}\n\n`;

    if (caption) {
      prompt += `LEGENDA ORIGINAL: "${caption}"\n\n`;
    }

    if (username) {
      prompt += `USU√ÅRIO: @${username}\n\n`;
    }

    prompt += `INSTRU√á√ïES PARA O COMENT√ÅRIO:`;
    prompt += `- Seja natural e aut√™ntico`;
    prompt += `- M√°ximo de 2-3 frases`;
    prompt += `- Relacione com o conte√∫do visual analisado`;
    prompt += `- Use emojis apropriados (1-2 no m√°ximo)`;
    prompt += `- Evite ser gen√©rico ou rob√≥tico`;
    prompt += `- Seja positivo e engajador`;
    prompt += `- Em portugu√™s brasileiro`;
    prompt += `- Cometa algum erro de digita√ß√£o proposital para parecer humano`;
    prompt += `- N√ÉO mencione que voc√™ analisou um v√≠deo\n`;
    prompt += `Gere APENAS o coment√°rio, sem explica√ß√µes adicionais:`;

    const result = await model.generateContent(prompt);
    const response = await result.response;

    return response.text().trim();
  }
}